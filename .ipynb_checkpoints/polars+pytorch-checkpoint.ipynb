{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd31262-e12d-454f-8bfc-9fed23eedeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import heapq\n",
    "from typing import List\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cdd84-4ae5-40b5-b94d-a746ad9dd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('./support/tyc2-3.parquet')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbdb70-865c-4d1e-80a9-27c7b7478f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_cartesian(distances, ra, dec):\n",
    "    x = distances * torch.cos(dec) * torch.cos(ra)\n",
    "    y = distances * torch.cos(dec) * torch.sin(ra)\n",
    "    z = distances * torch.sin(dec)\n",
    "    return torch.stack((x, y, z), dim=1)\n",
    "\n",
    "def calculate_distances(coords):\n",
    "    dist_matrix = torch.cdist(coords, coords)\n",
    "    unique_distances = torch.unique(dist_matrix)\n",
    "    return unique_distances[unique_distances > 0]\n",
    "\n",
    "def distance_from_magnitude(m, M):\n",
    "    return 10**((m - M + 5) / 5)\n",
    "\n",
    "def distance_from_magnitude_tensor(m: torch.Tensor, M: torch.Tensor) -> torch.Tensor:\n",
    "    return 10**((m - M + 5) / 5)\n",
    "\n",
    "# one of the possibilities\n",
    "def tetrahedron_score(coords):\n",
    "    distances = calculate_distances(coords)\n",
    "    print(distances)\n",
    "    mean_distance = torch.mean(distances)\n",
    "    std_dev = torch.std(distances)\n",
    "\n",
    "    # Assuming std_dev is small enough, the score will be close to 1\n",
    "    # Otherwise, it will be closer to 0\n",
    "    score = math.exp(-std_dev.item() / mean_distance.item())\n",
    "    return score\n",
    "\n",
    "def square_score(tensor):\n",
    "    \"\"\"Return a measure of how close the points in a tensor are to forming a square,\n",
    "    as well as the standard deviation of their brightness.\"\"\"\n",
    "    \n",
    "    # Calculate pairwise distances based on the x and y coordinates (first two dimensions)\n",
    "    spatial_distances = torch.pdist(tensor, p=2)\n",
    "    print(spatial_distances)\n",
    "    \n",
    "    # Sort the distances\n",
    "    sorted_distances = torch.sort(spatial_distances)[0]\n",
    "    \n",
    "    # Take the 4 smallest distances and compute their standard deviation\n",
    "    std_of_smallest_4 = sorted_distances[:4].std().item()\n",
    "    \n",
    "    # # Calculate the standard deviation of the brightness (third dimension)\n",
    "    # brightness_std = tensor[:, 2].std().item()\n",
    "    \n",
    "    return std_of_smallest_4\n",
    "\n",
    "def measure_squareness_old(tensor):\n",
    "    \"\"\"\n",
    "    :param points: A tensor of shape (4, 2) representing the 4 2D points\n",
    "    :return: A float indicating the squareness. Closer to 1 means more square.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate pairwise distances based on the x and y coordinates (first two dimensions)\n",
    "    spatial_distances = torch.pdist(tensor, p=2)\n",
    "\n",
    "    # Sort the distances\n",
    "    distances = torch.sort(spatial_distances)[0]\n",
    "    \n",
    "    # Mean of sides and diagonals\n",
    "    mean_sides = torch.mean(distances[:4])\n",
    "    mean_diagonal = torch.mean(distances[4:])\n",
    "    \n",
    "    # Squareness measure\n",
    "    squareness = mean_diagonal / mean_sides\n",
    "    \n",
    "    # Normalize with sqrt(2) to get values closer to 1 for squares\n",
    "    return abs(1 - (squareness / torch.sqrt(torch.tensor(2.0)).item()))\n",
    "\n",
    "def measure_squareness(tensor):\n",
    "    # Calculate pairwise distances based on the x and y coordinates (first two dimensions)\n",
    "    spatial_distances = torch.pdist(tensor, p=2)\n",
    "\n",
    "    # Sort the distances\n",
    "    distances = torch.sort(spatial_distances)[0]\n",
    "   \n",
    "    # Compute the standard deviation for the four shortest distances and the two longest distances\n",
    "    std_sides = torch.std(distances[:4])\n",
    "    std_diagonal = torch.std(distances[4:])\n",
    "    \n",
    "    # Ideally, for a perfect square, the standard deviations would be 0\n",
    "    # We use exp(-x) as a measure to get values close to 1 for low standard deviations\n",
    "    side_uniformity = torch.exp(-std_sides)\n",
    "    diagonal_uniformity = torch.exp(-std_diagonal)\n",
    "    \n",
    "    # Mean of sides and diagonals\n",
    "    mean_sides = torch.mean(distances[:4])\n",
    "    mean_diagonal = torch.mean(distances[4:])\n",
    "    \n",
    "    # Squareness measure based on side to diagonal ratio\n",
    "    squareness_ratio = mean_sides / mean_diagonal\n",
    "    \n",
    "    # Combine all the measures\n",
    "    # Normalize with sqrt(2) to get values closer to 1 for squares\n",
    "    final_squareness = (squareness_ratio / torch.sqrt(torch.tensor(2.0)).item()) * side_uniformity * diagonal_uniformity\n",
    "    \n",
    "    return abs(1 - final_squareness.item())\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# go from tycho2 to xyz coords\n",
    "def transform_radecmag_from_numpy(stars):\n",
    "    torch_tensors = [torch.from_numpy(star) for star in stars]\n",
    "    zeroes = torch.zeros(len(torch_tensors[2]))\n",
    "    print(\"one \", torch_tensors)\n",
    "    torch_tensors[2] = distance_from_magnitude_tensor(torch_tensors[2], zeroes)\n",
    "    print(\"two\", torch_tensors)\n",
    "    coords = convert_to_cartesian(*torch_tensors)\n",
    "    return coords\n",
    "\n",
    "def global_normalize_tensor(tensor):\n",
    "    \"\"\"Normalize a tensor based on its global min and max values. Also works for multiple tensors\"\"\"\n",
    "    global_min = torch.min(tensor)\n",
    "    global_max = torch.max(tensor)\n",
    "    \n",
    "    normalized = (tensor - global_min) / (global_max - global_min)\n",
    "    return normalized\n",
    "    \n",
    "def radec_normalize_tensor(tensors):\n",
    "    \"\"\"Normalize tensors based on their global min and max values, excluding the 3rd column.\"\"\"\n",
    "\n",
    "    # Concatenate tensors while excluding the 3rd column\n",
    "    # Drop the 3rd column from each tensor\n",
    "    tensor = tensors[:, :2]\n",
    "\n",
    "    # Compute global min and max excluding the 3rd column\n",
    "    global_min = torch.min(tensor)\n",
    "    global_max = torch.max(tensor)\n",
    "\n",
    "    # Normalize tensors using the computed global min and max\n",
    "    normalized = (tensor - global_min) / (global_max - global_min)\n",
    "    return normalized\n",
    "\n",
    "def mag_score(tensor):\n",
    "    # Computing the standard deviation\n",
    "    # stdev = t[:, 2].std()\n",
    "    max = tensor[:, 2].max()\n",
    "    min = tensor[:, 2].min()\n",
    "    return max - min\n",
    "\n",
    "def score_triangle(tensor):    \n",
    "    # Calculate pairwise distances based on the x and y coordinates (first two dimensions)\n",
    "    spatial_distances = torch.pdist(tensor, p=2)\n",
    "    \n",
    "    # Normalize with sqrt(2) to get values closer to 1 for squares\n",
    "    return torch.std(spatial_distances)\n",
    "\n",
    "def stars_for_point_and_radius(df, point, radius, max_mag):\n",
    "    \"\"\" point is in the corner, not the center \"\"\"\n",
    "    ra, dec = point\n",
    "    minra = ra\n",
    "    maxra = ra + radius\n",
    "    mindec = dec\n",
    "    maxdec = dec + radius\n",
    "    return df.filter((pl.col(\"RAmdeg\") < maxra) & (pl.col(\"RAmdeg\") > minra) & (pl.col(\"DEmdeg\") < maxdec) & (pl.col(\"DEmdeg\") > mindec) & (pl.col(\"Vmag\") <= max_mag))\n",
    "\n",
    "def stars_for_center_and_radius(df, center, radius, max_mag):\n",
    "    ra, dec = center\n",
    "    minra = ra - radius/2\n",
    "    maxra = ra + radius/2\n",
    "    mindec = dec - radius/2\n",
    "    maxdec = dec + radius/2\n",
    "    return df.filter((pl.col(\"RAmdeg\") < maxra) & (pl.col(\"RAmdeg\") > minra) & (pl.col(\"DEmdeg\") < maxdec) & (pl.col(\"DEmdeg\") > mindec) & (pl.col(\"Vmag\") <= max_mag))\n",
    "\n",
    "\n",
    "def get_grid_points(min_dec=-90, max_dec=90):\n",
    "    RA_values = [ra for ra in range(0, 361, 4)]  # Increment by 4 for a 2-degree radius\n",
    "    Dec_values = [dec for dec in range(min_dec, max_dec+1, 4)]  # Increment by 4 for a 2-degree radius\n",
    "    grid_points = [(ra, dec) for ra in RA_values for dec in Dec_values]\n",
    "    return grid_points\n",
    "\n",
    "def get_grid_point_by_idx(idx):\n",
    "    gp = get_grid_points()\n",
    "    return gp[idx]\n",
    "\n",
    "def get_region(df, idx, radius, max_mag):\n",
    "    center = get_grid_point_by_idx(idx)\n",
    "    return stars_for_center_and_radius(df, center, radius, max_mag)\n",
    "\n",
    "resultdf = pl.DataFrame({\n",
    "    \"score\": pl.Float64,\n",
    "    \"region\": pl.Int64,\n",
    "    \"item\": []\n",
    "})\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "@dataclass(order=True)\n",
    "class ScoreItem:\n",
    "    score: float\n",
    "    region: int=field(compare=False)\n",
    "    item: Any=field(compare=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14af751-acc8-4e2d-90c2-a2d2e43d17c6",
   "metadata": {},
   "source": [
    "## Code to process each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010edfa5-253a-48dc-869f-6ab1103be3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from heapq import heappush, heappushpop\n",
    "\n",
    "first = lambda h: 2**h - 1      # H stands for level height\n",
    "last = lambda h: first(h + 1)\n",
    "level = lambda heap, h: heap[first(h):last(h)]\n",
    "prepare = lambda e, field: str(e).center(field)\n",
    "def hprint(heap, width=None):\n",
    "    if width is None:\n",
    "        width = max(len(str(e)) for e in heap)\n",
    "    height = int(math.log(len(heap), 2)) + 1\n",
    "    gap = ' ' * width\n",
    "    for h in range(height):\n",
    "        below = 2 ** (height - h - 1)\n",
    "        field = (2 * below - 1) * width\n",
    "        print(gap.join(prepare(e, field) for e in level(heap, h)))\n",
    "        \n",
    "def process(stars, region, point, nr_stars) -> List[ScoreItem]:\n",
    "    tensor = torch.tensor(stars.to_numpy())\n",
    "    print(tensor.shape)\n",
    "    combs = list(combinations(range(len(stars)), nr_stars))\n",
    "    indices = torch.tensor(combs, dtype=torch.long)\n",
    "    tensor_combinations = tensor[indices]\n",
    "    heap = []\n",
    "    for entry in tqdm.tqdm(tensor_combinations):\n",
    "        norm_radec = radec_normalize_tensor(entry)\n",
    "        b = mag_score(entry)\n",
    "        if b > 1:\n",
    "            continue\n",
    "        a = score_triangle(norm_radec)     \n",
    "        score = a+b\n",
    "        item = (a,b,entry)\n",
    "        if len(heap) < 2:\n",
    "            heappush(heap, ScoreItem(score, region, item))\n",
    "        else:\n",
    "            heappushpop(heap, ScoreItem(score, region, item))\n",
    "    print(f\"Processed {region=} - {point} for length {len(stars)} with {len(tensor_combinations)=}\")\n",
    "    return heap\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fe785-7203-4af0-83f2-eb46e48d9d0e",
   "metadata": {},
   "source": [
    "## Code to save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6adf7-cea5-4464-a70c-2a1cca7a7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_result_and_save(resultdf, heap: List[ScoreItem], filename):\n",
    "    for entry in heap:\n",
    "        thisdf = pl.DataFrame({\n",
    "            \"score\": entry.score, \n",
    "            \"region\": entry.region, \n",
    "            \"score1\": entry.item[0],\n",
    "            \"score2\": entry.item[1],\n",
    "            \"stars\": [entry.item[2].tolist()],\n",
    "        })\n",
    "        if resultdf.is_empty():\n",
    "            resultdf = thisdf\n",
    "        else:\n",
    "            resultdf = pl.concat([resultdf, thisdf])\n",
    "    resultdf.write_parquet(filename)\n",
    "    return resultdf\n",
    "# Define the schema\n",
    "# Define the schema\n",
    "schema = {\n",
    "    \"score\": pl.Float64,\n",
    "    \"region\": pl.Float64,\n",
    "    \"score1\": pl.Float64,\n",
    "    \"score2\": pl.Float64,\n",
    "    \"stars\": pl.List(pl.List(pl.Float64))  # Nested list type\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeec4d6-a7a4-4a57-9554-c26435a49e76",
   "metadata": {},
   "source": [
    "## Generate a grid of regions and process each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44094d2-35ad-472a-8495-59680666e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points = get_grid_points(-63,63)\n",
    "print(\"Total grid points is:\", len(grid_points))\n",
    "global_heap=[]\n",
    "result_filename = 'result_squareness.parquet'\n",
    "resultdf = pl.DataFrame()\n",
    "try:\n",
    "    resultdf = pl.read_parquet(result_filename)\n",
    "except:\n",
    "    print(\"no previoous results\")\n",
    "    pass\n",
    "print(f\"Loaded results: {resultdf.head()}\")\n",
    "\n",
    "def process_regions(resultdf, grid, start=0, end=0):\n",
    "    if end == 0:\n",
    "        end = len(grid)\n",
    "    \n",
    "    zipped_list = list(zip(range(len(grid)), grid))\n",
    "    grid_points = zipped_list[start:end]\n",
    "\n",
    "    result = []\n",
    "    for idx, point in tqdm.tqdm(grid_points):\n",
    "        stars = stars_for_point_and_radius(df, point=point, radius=2, max_mag=10)\n",
    "        if len(stars) > 0:\n",
    "            best = heapq.nsmallest(1, global_heap)\n",
    "            beststr = f\"{best[0].score:.5f}\" if best else 0\n",
    "            print(f\"\\n\\n---- Region: {idx}, {len(stars)} stars, best is {beststr} global_heap is now {len(global_heap)} --------\")\n",
    "            heap = process(stars, idx, point, 3)\n",
    "            if heap:\n",
    "                hprint(heap if heap else []) \n",
    "            else:\n",
    "                print(\"no results\")\n",
    "            print(\"************************\")\n",
    "            for h in heap:\n",
    "                heappush(global_heap, h)\n",
    "                result.append([\n",
    "                 h.score.item(), \n",
    "                 h.region, \n",
    "                 h.item[0].item(),\n",
    "                 h.item[1].item(),\n",
    "                 h.item[2].tolist()\n",
    "                ]\n",
    "                )\n",
    "        if idx % 10:\n",
    "            #resultdf = add_to_result_and_save(resultdf, heap, result_filename)\n",
    "            resultdf = pl.DataFrame(result) #, schema=schema)\n",
    "            resultdf = resultdf.rename({'column_0': 'score', 'column_1': 'region', 'column_2': 'score1', 'column_3': 'score2',\n",
    "                             'column_4': 'stars'})\n",
    "            resultdf.write_parquet(result_filename)\n",
    "            print(resultdf.sort(\"score\").head(5) if not resultdf.is_empty() else \"no score\")\n",
    "    #time.sleep(10)\n",
    "process_regions(resultdf, grid_points, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fa4d8-1453-4c38-bdd4-9377585af73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[352.9835510253906, -61.950279235839844, 9.794389724731445], [352.44195556640625, -61.28193664550781, 9.73677921295166], [352.8981628417969, -62.92292022705078, 9.376359939575195], [353.7196960449219, -62.507789611816406, 9.891069412231445]]\n",
    "square_score(radec_normalize_tensor(torch.Tensor(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39042ae-9141-4704-9f7f-af41c3c6f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "points = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "print(measure_squareness(points))  # This should be close to 1 for a square\n",
    "print(measure_squareness(torch.tensor(a)))  # This should be close to 1 for a square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a75e2-19f6-4371-8c1b-f3f3ad97b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing mplot3d toolkits\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import torch\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])  # set width ratio for each subplot\n",
    "coords = torch.tensor(a)\n",
    "# First subplot with one viewing angle\n",
    "ax1 = fig.add_subplot(gs[0], projection='3d')\n",
    "ax1.scatter(coords[:, 0], coords[:, 1], coords[:, 2], c='green')\n",
    "ax1.view_init(30, 30)  # Set elevation and azimuth\n",
    "ax1.set_title('View 1')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "\n",
    "# Second subplot with another viewing angle\n",
    "ax2 = fig.add_subplot(gs[1], projection='3d')\n",
    "ax2.scatter(coords[:, 0], coords[:, 1], coords[:, 2], c='green')\n",
    "ax2.view_init(30, 120)  # Different elevation and azimuth\n",
    "ax2.set_title('View 2')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "\n",
    "plt.suptitle('xyz projection for stars from different views')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926570f-5a08-46c6-a3e9-b15c690cf68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
